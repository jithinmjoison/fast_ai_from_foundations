{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2oMnXXdRWIBjbaCwJ/ekZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jithinmjoison/fast_ai_from_foundations/blob/main/LLM_from_scratch_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86EZTyGNswsB",
        "outputId": "a3427904-db45-4170-fe39-5e9011c151f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.5.1+cu124\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from importlib.metadata import version\n",
        "\n",
        "print(\"torch version:\", version(\"torch\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###Prior to Transformers, RNNs were used for ###"
      ],
      "metadata": {
        "id": "IcnfyFGLs-xs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self Attention is the reason why transformer architecture works"
      ],
      "metadata": {
        "id": "oyrH6eyowpUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Sample for simple architecture ##\n",
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")\n"
      ],
      "metadata": {
        "id": "pKKhVYtbwSNY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1]  # 2nd input token is the query\n",
        "\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "for i, x_i in enumerate(inputs):\n",
        "    attn_scores_2[i] = torch.dot(x_i, query) # dot product (transpose not necessary here since they are 1-dim vectors)\n",
        "\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inUhzMDQxUjv",
        "outputId": "ea5d54d9-a4c9-4a63-be86-c6b98e81598d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yaKTJGAyxtAA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}